{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplabcut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "video_paths = [\"/home/antortjim/MEGA/FlySleepLab/FlyVideos/outpy0{}.avi\".format(e) for e in range(4,5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Create a new project\n",
    "\n",
    "Pass name, author, path to videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run only once\n",
    "# config_path = deeplabcut.create_new_project('Arena','El-Sayed', video_paths, copy_videos=False)\n",
    "# print(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Configure the project\n",
    "\n",
    "Edit the config.yaml file to define\n",
    "\n",
    "- features to be extracted (**bodyparts**): head and tail\n",
    "- region of interest (**x1, x2, y1, y2**): a rectangle around the 4 arenas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/antortjim/MEGA/FlySleepLab/DeepLabCut/examples/Arena-El-Sayed-2019-02-03/config.yaml'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_path = \"/home/antortjim/MEGA/FlySleepLab/DeepLabCut/examples/Arena-El-Sayed-2019-02-03/config.yaml\"\n",
    "from shutil import copyfile\n",
    "# copyfile(\"/home/antortjim/Desktop/config.yaml\", config_path)\n",
    "\n",
    "# config_path=\"/home/antortjim/MEGA/FlySleepLab/DeepLabCut/examples/Reaching-Mackenzie-2018-08-30/config.yaml\"\n",
    "deeplabcut.utils.auxiliaryfunctions.read_config(config_path)\n",
    "config_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Task': 'Arena',\n",
       " 'scorer': 'El-Sayed',\n",
       " 'date': 'Feb3',\n",
       " 'project_path': '/home/antortjim/MEGA/FlySleepLab/DeepLabCut/examples/Arena-El-Sayed-2019-02-03',\n",
       " 'video_sets': {'/home/antortjim/MEGA/FlySleepLab/FlyVideos/outpy04.avi': {'crop': '409, 797, 746, 819'}},\n",
       " 'bodyparts': ['Head', 'Tail'],\n",
       " 'start': 0,\n",
       " 'stop': 1,\n",
       " 'numframes2pick': 25,\n",
       " 'pcutoff': 0.1,\n",
       " 'dotsize': 12,\n",
       " 'alphavalue': 0.7,\n",
       " 'colormap': 'hsv',\n",
       " 'TrainingFraction': [0.95],\n",
       " 'iteration': 0,\n",
       " 'resnet': 50,\n",
       " 'snapshotindex': -1,\n",
       " 'batch_size': 4,\n",
       " 'cropping': False,\n",
       " 'x1': 409,\n",
       " 'x2': 797,\n",
       " 'y1': 746,\n",
       " 'y2': 819,\n",
       " 'corner2move2': [50, 50],\n",
       " 'move2corner': True}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "with open(config_path, 'r') as ymlfile: \n",
    "    cfg = yaml.load(ymlfile)\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "videos = cfg['video_sets'].keys()\n",
    "video = list(enumerate(videos))[0][1]\n",
    "cap=cv2.VideoCapture(video)\n",
    "fps = cap.get(5) #https://docs.opencv.org/2.4/modules/highgui/doc/reading_and_writing_images_and_video.html#videocapture-get\n",
    "nframes = int(cap.get(7))\n",
    "duration=nframes*1./fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n",
      "173\n",
      "17.3\n",
      "['409', ' 797', ' 746', ' 819']\n"
     ]
    }
   ],
   "source": [
    "print(fps)\n",
    "print(nframes)\n",
    "print(duration)\n",
    "start=0\n",
    "stop=1\n",
    "import numpy as np\n",
    "int(start*duration+np.random.rand()*duration*(stop-start))\n",
    "coords = cfg['video_sets'][video]['crop'].split(',')\n",
    "print(coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/antortjim/MEGA/FlySleepLab/DeepLabCut/examples/Arena-El-Sayed-2019-02-03/labeled-data/outpy04')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "fname = Path(video)\n",
    "output_path = Path(config_path).parents[0] / 'labeled-data' / fname.stem\n",
    "output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Extract frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file read successfully.\n",
      "Make sure you change the crop parameters in the config.yaml file. The default parameters are set to the video dimensions.\n",
      "Extracting frames based on uniform ...\n",
      "Uniformly extracting of frames from 0.0  seconds to 17.3  seconds.\n",
      "[  0 124 107  76 118   1  95   5 122 159  66 137 133  72 153 106  29  87\n",
      "  17  84 140  33  24  28]\n",
      "Hello Antonio\n",
      "\n",
      "Frames were selected.\n",
      "You can now label the frames using the function 'label_frames' (if you extracted enough frames for all videos).\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.extract_frames(config_path, mode='automatic', algo=\"uniform\", userfeedback=False, crop=True, checkcropping=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D. Label frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on folder: outpy04\n",
      "You can now check the labels, using 'check_labels' before proceeding. Then,  you can use the function 'create_training_dataset' to create the training dataset.\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.label_frames(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E. Check frame labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating images with labels by El-Sayed.\n",
      "/home/antortjim/MEGA/FlySleepLab/DeepLabCut/examples/Arena-El-Sayed-2019-02-03/labeled-data/outpy04_labeled  already exists!\n",
      "They are stored in the following folder: /home/antortjim/MEGA/FlySleepLab/DeepLabCut/examples/Arena-El-Sayed-2019-02-03/labeled-data/outpy04_labeled.\n",
      "If all the labels are ok, then use the function 'create_training_dataset' to create the training dataset!\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.check_labels(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K. Refine labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/antortjim/MEGA/FlySleepLab/DeepLabCut/examples/Arena-El-Sayed-2019-02-03/labeled-data/outpy04\n",
      "Closing... you did not hit save!\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.refine_labels(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F. Create training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.create_training_dataset(config_path,num_shuffles=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## G. Train The network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1]],\n",
      " 'all_joints_names': ['Head', 'Tail'],\n",
      " 'batch_size': 1,\n",
      " 'bottomheight': 400,\n",
      " 'crop': True,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_ArenaFeb3/Arena_El-Sayed95shuffle1.mat',\n",
      " 'dataset_type': 'default',\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': '/home/antortjim/anaconda3/envs/DLC/lib/python3.6/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'leftwidth': 400,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_ArenaFeb3/Documentation_data-Arena_95shuffle1.pickle',\n",
      " 'minsize': 100,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 2,\n",
      " 'optimizer': 'sgd',\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': '/home/antortjim/MEGA/FlySleepLab/DeepLabCut/examples/Arena-El-Sayed-2019-02-03',\n",
      " 'regularize': False,\n",
      " 'rightwidth': 400,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': '/home/antortjim/MEGA/FlySleepLab/DeepLabCut/examples/Arena-El-Sayed-2019-02-03/dlc-models/iteration-0/ArenaFeb3-trainset95shuffle1/train/snapshot',\n",
      " 'stride': 8.0,\n",
      " 'topheight': 400,\n",
      " 'use_gt_segm': False,\n",
      " 'video': False,\n",
      " 'video_batch': False,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/antortjim/MEGA/FlySleepLab/DeepLabCut/examples/Arena-El-Sayed-2019-02-03/config.yaml\n",
      "Model folder name is  dlc-models/iteration-0/ArenaFeb3-trainset95shuffle1\n",
      "Loading pose config file in /home/antortjim/MEGA/FlySleepLab/DeepLabCut/examples/Arena-El-Sayed-2019-02-03/dlc-models/iteration-0/ArenaFeb3-trainset95shuffle1/train/pose_cfg.yaml\n",
      "> \u001b[0;32m/home/antortjim/anaconda3/envs/DLC/lib/python3.6/site-packages/deeplabcut/pose_estimation_tensorflow/train.py\u001b[0m(89)\u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     88 \u001b[0;31m    \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 89 \u001b[0;31m    \u001b[0mbatch_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batch_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     90 \u001b[0;31m    \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menqueue_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplaceholders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msetup_preloading\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "<deeplabcut.pose_estimation_tensorflow.dataset.pose_dataset.PoseDataset object at 0x7f0f3de48eb8>\n",
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'cfg', 'compute_scmap_weights', 'compute_target_part_scoremap', 'curr_img', 'data', 'get_scale', 'get_training_sample', 'has_gt', 'is_valid_size', 'load_dataset', 'make_batch', 'mirror_joint_coords', 'mirror_joints', 'next_batch', 'next_training_sample', 'num_images', 'num_training_samples', 'raw_data', 'set_shuffle', 'set_test_mode', 'shuffle', 'shuffle_images']\n",
      "[<deeplabcut.pose_estimation_tensorflow.dataset.pose_dataset.DataItem object at 0x7f0f3ddf8390>, <deeplabcut.pose_estimation_tensorflow.dataset.pose_dataset.DataItem object at 0x7f0f3de48d68>, <deeplabcut.pose_estimation_tensorflow.dataset.pose_dataset.DataItem object at 0x7f0f3ddf8080>, <deeplabcut.pose_estimation_tensorflow.dataset.pose_dataset.DataItem object at 0x7f0f3ddf8048>, <deeplabcut.pose_estimation_tensorflow.dataset.pose_dataset.DataItem object at 0x7f0f3ddf82e8>, <deeplabcut.pose_estimation_tensorflow.dataset.pose_dataset.DataItem object at 0x7f0f3ddf86d8>, <deeplabcut.pose_estimation_tensorflow.dataset.pose_dataset.DataItem object at 0x7f0f3ddf8668>, <deeplabcut.pose_estimation_tensorflow.dataset.pose_dataset.DataItem object at 0x7f0f3ddf87b8>, <deeplabcut.pose_estimation_tensorflow.dataset.pose_dataset.DataItem object at 0x7f0f3ddf8710>, <deeplabcut.pose_estimation_tensorflow.dataset.pose_dataset.DataItem object at 0x7f0f3ddf8240>, <deeplabcut.pose_estimation_tensorflow.dataset.pose_dataset.DataItem object at 0x7f0f3ddf8780>, <deeplabcut.pose_estimation_tensorflow.dataset.pose_dataset.DataItem object at 0x7f0f3ddf8860>, <deeplabcut.pose_estimation_tensorflow.dataset.pose_dataset.DataItem object at 0x7f0f3ddf87f0>, <deeplabcut.pose_estimation_tensorflow.dataset.pose_dataset.DataItem object at 0x7f0f3ddf8940>, <deeplabcut.pose_estimation_tensorflow.dataset.pose_dataset.DataItem object at 0x7f0f3ddf8828>, <deeplabcut.pose_estimation_tensorflow.dataset.pose_dataset.DataItem object at 0x7f0f3ddf8978>, <deeplabcut.pose_estimation_tensorflow.dataset.pose_dataset.DataItem object at 0x7f0f3ddf88d0>, <deeplabcut.pose_estimation_tensorflow.dataset.pose_dataset.DataItem object at 0x7f0f3ddf8ac8>, <deeplabcut.pose_estimation_tensorflow.dataset.pose_dataset.DataItem object at 0x7f0f3ddf8a58>, <deeplabcut.pose_estimation_tensorflow.dataset.pose_dataset.DataItem object at 0x7f0f3ddf8a20>, <deeplabcut.pose_estimation_tensorflow.dataset.pose_dataset.DataItem object at 0x7f0f3ddf8908>]\n",
      "21\n",
      "<deeplabcut.pose_estimation_tensorflow.dataset.pose_dataset.DataItem object at 0x7f0f3ddf8390>\n",
      "<class 'deeplabcut.pose_estimation_tensorflow.dataset.pose_dataset.DataItem'>\n",
      "{'part_loss': <tf.Tensor 'sigmoid_cross_entropy_loss/value:0' shape=() dtype=float32>, 'locref_loss': <tf.Tensor 'mul:0' shape=() dtype=float32>, 'total_loss': <tf.Tensor 'add:0' shape=() dtype=float32>}\n",
      "\n",
      "Program interrupted. (Use 'cont' to resume).\n",
      "--Call--\n",
      "> \u001b[0;32m/home/antortjim/anaconda3/envs/DLC/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m(2793)\u001b[0;36m_check_not_finalized\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   2792 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 2793 \u001b[0;31m  \u001b[0;32mdef\u001b[0m \u001b[0m_check_not_finalized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   2794 \u001b[0;31m    \"\"\"Check if the graph is finalized.\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# ! export CUDA_VISIBLE_DEVICES=''\n",
    "print(config_path)\n",
    "deeplabcut.train_network(config_path,shuffle=1, displayiters=10, saveiters=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mdeeplabcut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shuffle=1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'trainingsetindex=0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gputouse=None'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'max_snapshots_to_keep=5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'autotune=False'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'displayiters=None'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'saveiters=None'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'maxiters=None'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "\u001b[0;32mdef\u001b[0m \u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainingsetindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgputouse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_snapshots_to_keep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mautotune\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdisplayiters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msaveiters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmaxiters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Trains the network with the labels in the training dataset.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Parameter\u001b[0m\n",
       "\u001b[0;34m    ----------\u001b[0m\n",
       "\u001b[0;34m    config : string\u001b[0m\n",
       "\u001b[0;34m        Full path of the config.yaml file as a string.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    shuffle: int, optional\u001b[0m\n",
       "\u001b[0;34m        Integer value specifying the shuffle index to select for training. Default is set to 1\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    trainingsetindex: int, optional\u001b[0m\n",
       "\u001b[0;34m        Integer specifying which TrainingsetFraction to use. By default the first (note that TrainingFraction is a list in config.yaml).\u001b[0m\n",
       "\u001b[0;34m    \u001b[0m\n",
       "\u001b[0;34m    gputouse: int, optional. Natural number indicating the number of your GPU (see number in nvidia-smi). If you do not have a GPU put None.\u001b[0m\n",
       "\u001b[0;34m    See: https://nvidia.custhelp.com/app/answers/detail/a_id/3751/~/useful-nvidia-smi-queries\u001b[0m\n",
       "\u001b[0;34m    \u001b[0m\n",
       "\u001b[0;34m    Additional parameters:\u001b[0m\n",
       "\u001b[0;34m    \u001b[0m\n",
       "\u001b[0;34m    max_snapshots_to_keep: int, or None. Sets how many snapshots are kept, i.e. states of the trained network. Every savinginteration many times \u001b[0m\n",
       "\u001b[0;34m    a snapshot is stored, however only the last max_snapshots_to_keep many are kept! If you change this to None, then all are kept. \u001b[0m\n",
       "\u001b[0;34m    See: https://github.com/AlexEMG/DeepLabCut/issues/8#issuecomment-387404835\u001b[0m\n",
       "\u001b[0;34m    \u001b[0m\n",
       "\u001b[0;34m    autotune: property of TensorFlow, somehow faster if 'false' (as Eldar found out, see https://github.com/tensorflow/tensorflow/issues/13317). Default: False\u001b[0m\n",
       "\u001b[0;34m    \u001b[0m\n",
       "\u001b[0;34m    displayiters: this variable is actually set in pose_config.yaml. However, you can overwrite it with this hack. Don't use this regularly, just if you are too lazy to dig out \u001b[0m\n",
       "\u001b[0;34m    the pose_config.yaml file for the corresponding project. If None, the value from there is used, otherwise it is overwritten! Default: None\u001b[0m\n",
       "\u001b[0;34m    \u001b[0m\n",
       "\u001b[0;34m    saveiters: this variable is actually set in pose_config.yaml. However, you can overwrite it with this hack. Don't use this regularly, just if you are too lazy to dig out \u001b[0m\n",
       "\u001b[0;34m    the pose_config.yaml file for the corresponding project. If None, the value from there is used, otherwise it is overwritten! Default: None\u001b[0m\n",
       "\u001b[0;34m    \u001b[0m\n",
       "\u001b[0;34m    maxiters: this variable is actually set in pose_config.yaml. However, you can overwrite it with this hack. Don't use this regularly, just if you are too lazy to dig out \u001b[0m\n",
       "\u001b[0;34m    the pose_config.yaml file for the corresponding project. If None, the value from there is used, otherwise it is overwritten! Default: None\u001b[0m\n",
       "\u001b[0;34m    \u001b[0m\n",
       "\u001b[0;34m    Example\u001b[0m\n",
       "\u001b[0;34m    --------\u001b[0m\n",
       "\u001b[0;34m    for training the network for first shuffle of the training dataset.\u001b[0m\n",
       "\u001b[0;34m    >>> deeplabcut.train_network('/analysis/project/reaching-task/config.yaml')\u001b[0m\n",
       "\u001b[0;34m    --------\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    for training the network for second shuffle of the training dataset.\u001b[0m\n",
       "\u001b[0;34m    >>> deeplabcut.train_network('/analysis/project/reaching-task/config.yaml',shuffle=2)\u001b[0m\n",
       "\u001b[0;34m    --------\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mfrom\u001b[0m \u001b[0mdeeplabcut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpose_estimation_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mfrom\u001b[0m \u001b[0mdeeplabcut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mauxiliaryfunctions\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mstart_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;31m# Read file path for pose_config file. >> pass it on\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauxiliaryfunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmodelfoldername\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauxiliaryfunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetModelFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"TrainingFraction\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrainingsetindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mposeconfigfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'project_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelfoldername\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"pose_cfg.yaml\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model folder name is  {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelfoldername\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading pose config file in {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposeconfigfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mposeconfigfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m      \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The training datafile \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposeconfigfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" is not present.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m      \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Probably, the training dataset for this secific shuffle index was not created.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m      \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Try with a different shuffle/trainingsetfraction or use function 'create_training_dataset' to create a new trainingdataset with this shuffle index.\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m      \u001b[0;31m# Set environment variables\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m      \u001b[0;32mif\u001b[0m \u001b[0mautotune\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#see: https://github.com/tensorflow/tensorflow/issues/13317\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m          \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TF_CUDNN_USE_AUTOTUNE'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'0'\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m      \u001b[0;32mif\u001b[0m \u001b[0mgputouse\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CUDA_VISIBLE_DEVICES'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgputouse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CUDA_VISIBLE_DEVICES is {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgputouse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m      \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m          \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposeconfigfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdisplayiters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msaveiters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmaxiters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_to_keep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_snapshots_to_keep\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#pass on path and file name for pose_cfg.yaml!\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m      \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m          \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m      \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m          \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m      \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The network is now trained and ready to evaluate. Use the function 'evaluate_network' to evaluate the network.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/envs/DLC/lib/python3.6/site-packages/deeplabcut/pose_estimation_tensorflow/training.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "deeplabcut.train_network??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLC",
   "language": "python",
   "name": "dlc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
